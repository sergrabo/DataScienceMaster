{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minería de Datos (Master en Data Science, UIMP-UC)\n",
    "\n",
    "## S11. Intercomparación de técnicas para clasificación\n",
    "\n",
    "### Rodrigo Manzanas   \n",
    "#### 9 Diciembre 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "En esta práctica haremos una intercomparación de varias de las técnicas vistas hasta ahora para problemas de clasificación: árboles, modelos lineales generalizados (GLMs) y k-NN. Por tanto, pretende ser un repaso general cuyo objetivo es ayudaros a afianzar el manejo de estas técnicas (y los correspondientes aquetes de `R`) para un caso de estudio concreto: la predicción del evento binario ocurrencia de precipitación (lluvia sí/lluvia no)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzaremos cargando el dataset `meteo`, que ya ha sido utilizado en sesiones anteriores. Como sabéis, la variable objetivo en este dataset es la precipitation diaria en Lisboa durante el período 1979-2008, y para predecirla se dispone de 320 predictores que describen la circulación atmosférica de larga escala. Dichos predictores corresponden a un conjunto de 8 variables meteorológicas\n",
    "* altura geopotencial en 500 hPa\n",
    "* temperatura en superficie, en 850 hPa, 700 hPa y 500 hPa\n",
    "* humedad específica en 850 hPa y 500 hPa\n",
    "* presión a nivel del mar\n",
    "\n",
    "definidas sobre un dominio geográfico que incluye 40 puntos sobre la península Ibérica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading data\n",
    "data = read.csv(\"/home/jovyan/DataMining/Data/meteo.csv\")\n",
    "y = data[, 2]  # predictand\n",
    "x = data[, -c(1,2)]  # predictors\n",
    "length(y)\n",
    "dim(x)\n",
    "rm(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para agilizar los tiempos de cómputo, reduciremos la dimensionalidad de nuetro problema. Una alternativa para tal fin es el uso de componentes principales (PCs, en inglés). Sin embargo, para no limitar la interpretabilidad de los resultados obtenidos con árboles, utilizaremos otra aproximación aquí. En concreto, optaremos por un análisis de correlaciones, en el que se calcula la correlación de Spearman entre nuestra variable objetivo y todas las variables predictoras disponibles. La idea es que, cuanto más fuerte sea esta correlación, mayor es el vínculo físico entre predictando y predictor, y por tanto, más útil es la información que nos aporta ese predictor. Este análisis nos permite descartar predictores poco relevantes.\n",
    "Siguiendo esta idea, calcularemos la correlación existente entre nuestro predictando y los 320 predictores, y eliminaremos aquellos con correlaciones entre -0.4 y 0.4. ¿Cuánto se ha reducido la dimensionalidad del problema?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## informed selection of predictors, based on a correlation analysis\n",
    "r.xy = c()\n",
    "for (ivar in 1:ncol(x)) {\n",
    "  r.xy[ivar] = cor(***)\n",
    "}\n",
    "plot(***)\n",
    "\n",
    "ind.sele = which(*** > 0.4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para simplificar aún más los cálculos, nos limitaremos a los primeros 5000 días del dataset. Como hemos hecho otras veces, consideraremos una partición de la muestra en dos subconjuntos independientes, train y test, escogidos aleatoriamente (75% para entrenar y 25% para testear)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping only 5000 days for this example\n",
    "n = 5000\n",
    "y = y[1:n]\n",
    "x = x[1:n, ind.sele]\n",
    "\n",
    "# train/test partition\n",
    "set.seed(0)\n",
    "indtrain = sample(1:n, round(0.75*n))  \n",
    "indtest = setdiff(1:n, indtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árboles de clasificación\n",
    "\n",
    "En primer lugar, tenemos que crear la variable binaria ocurrencia de precipitación (considera un umbral de 1mm). A partir de esta nueva variable (*occ*), de tipo factor, construiremos el dataframe asociado al problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary occurrence\n",
    "occ = y\n",
    "occ[which(y < 1)] = 0  # dry day\n",
    "occ[which(y >= 1)] = 1  # rainy day\n",
    "\n",
    "# dataframe for occurrence\n",
    "df.occ = data.frame(y.occ = as.factor(occ), predictors = x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación construiremos el árbol completo (usa la función *tree*). ¿Cuántos nodos terminales (hojas) obtienes? ¿Qué variables predictoras dan lugar a las primeras divisiones del árbol?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## complete tree (based on training dataset)\n",
    "library(tree)\n",
    "t.occ = tree(***)\n",
    "plot(t.occ); text(t.occ, pretty = F)\n",
    "summary(t.occ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para simplificar este árbol tan complejo tendremos que podarlo adecuadamente (*prune.tree*). Utiliza una cross-validación con un 10-fold (*cv.tree*) para encontrar el número de hojas del árbol óptimo. ¿Cuál es este número? ¿Qué predictores aparecen como los más importantes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 10-fold cross-validation for determining optimum number of leaves\n",
    "t.occ.cv = cv.tree(***)\n",
    "plot(***)  # deviance as a function of number of leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pruning\n",
    "t.occ.opt = prune.tree(***)\n",
    "plot(t.occ.opt); text(t.occ.opt)\n",
    "summary(t.occ.opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la vista de la representación gráfica del árbol, ya sabes cuál será la profundidad (número de niveles verticales) óptima. Utiliza el paquete *rpart* para entrenar un árbol con esa profundidad, represéntalo (*rpart.plot*) y comprueba si hay diferencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(rpart)\n",
    "t.occ.opt2 = rpart(***)\n",
    "\n",
    "library(rpart.plot)\n",
    "rpart.plot(***)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliza los dos árboles para predecir en el test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## occurrence prediction for test\n",
    "# tree fitted with 'tree'\n",
    "pred.t.occ = predict(***, type = \"class\")\n",
    "str(pred.t.occ)\n",
    "\n",
    "# tree fitted with 'rpart'\n",
    "pred.t.occ2 = predict(***, type = \"class\")\n",
    "str(pred.t.occ2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valida tus predicciones en función del accuracy (tasa de ciertos) y la correlación de Spearman. Esta última nos dará una idea de lo bien/mal que la predicción reproduce la estructura temporal de la serie observada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## validation\n",
    "# accuracy \n",
    "acc.t = ***\n",
    "acc.t2 = ***\n",
    "c(acc.t, acc.t2)\n",
    "\n",
    "# correlation\n",
    "cor.t = ***\n",
    "cor.t2 = ***\n",
    "c(cor.t, cor.t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como último ejercicio con árboles, utiliza esta vez *caret* para determinar la profundidad óptima del árbol. Para ello, barre profundidades de 1 a 20 considerando cross-validación 10-fold que repetirás 20 veces. A continuación, construye un árbol que tenga esa profundidad que has encontrado como óptima (*rpart*) y utilízalo para predecir en el test. Valida las predicciones que obtengas en función del accuracy y la correlación y compara los resultados con los que habías obtenido anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(caret)\n",
    "## finding optimum depth\n",
    "trctrl = trainControl(***)\n",
    "t.opt = train(***\n",
    "                method = \"rpart2\",\n",
    "                trControl = trctrl,                \n",
    "                ***)\n",
    "plot(t.opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## building tree up\n",
    "t.occ.opt3 = rpart(***)\n",
    "rpart.plot(t.occ.opt3, extra = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## occurrence prediction for test\n",
    "# tree fitted with 'rpart' (based on optimum configuration returned by caret)\n",
    "pred.t.occ3 = predict(***, type = \"class\")\n",
    "\n",
    "## validation\n",
    "# accuracy \n",
    "acc.t3 = ***\n",
    "\n",
    "# correlation\n",
    "cor.t3 = ***\n",
    "c(acc.t3, cor.t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos lineales generalizados (GLMs)\n",
    "\n",
    "Usaremos a continuación GLMs para el mismo problema. Dado que nuestra variable objetivo es binaria, utilizaremos la familia *binomial* con función de enlace *logit* (regresión logística) dentro de la función *glm* del paquete *stats*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GLM for occurrence\n",
    "glm.occ = glm(y.occ ~ ., df.occ, subset = indtrain, family = ***)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez tenemos el modelo, lo utilizamos para predecir en el test. Tendremos que convertir la predicción probabilística obtenida en binaria (considera para ello un umbral 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## occurrence prediction for test\n",
    "pred.glm.occ = predict(***, type = ***)\n",
    "str(pred.glm.occ)\n",
    "hist(pred.glm.occ, 100)\n",
    "pred.glm.occ = ifelse(***)\n",
    "str(pred.glm.occ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## validation\n",
    "# accuracy\n",
    "acc.glm = ***\n",
    "acc.glm\n",
    "\n",
    "# correlation\n",
    "cor.glm = ***\n",
    "cor.glm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, entrena otros dos GLMs, uno que considere como único predictor una de las variables con mayor poder explicativo y otro que utilice como único predictor cualquier otra variable. Básate en los árboles para hacer estas elecciones. Utiliza ambos GLMs para predecir en el test y valida tus predicciones en función del accuracy y la correlación. ¿Qué conclusiones obtienes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLM for occurrence (one good predictor)\n",
    "glm.occ2 = glm(y.occ ~ ***,\n",
    "              df.occ, subset = indtrain, family = ***)\n",
    "pred.glm.occ2 = predict(***, type = ***)\n",
    "pred.glm.occ2 = ifelse(***)\n",
    "acc.glm2 = ***\n",
    "cor.glm2 = ***\n",
    "c(acc.glm2, cor.glm2)\n",
    "\n",
    "# GLM for occurrence (one random predictor)\n",
    "glm.occ3 = glm(y.occ ~ ***,\n",
    "              df.occ, subset = indtrain, family = ***)\n",
    "pred.glm.occ3 = predict(***, type = ***)\n",
    "pred.glm.occ3 = ifelse(***)\n",
    "acc.glm3 = ***\n",
    "cor.glm3 = ***\n",
    "c(acc.glm3, cor.glm3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k nearest neighbors (k-NN)\n",
    "\n",
    "La última de las técnicas a utilizar será la k-NN. Comenzaremos por una versión de k-NN en la que sólo se considere el vecino más cercano (utiliza la función *knn* del paquete *class*). \n",
    "\n",
    "**Nota:** Recuerda que en la técnica k-NN es muy importante pre-procesar adecuadamente (estandarizar) los predictores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prediction for test (with k = 1)\n",
    "library(class)\n",
    "pred.knn1 = knn(train = scale(***), \n",
    "                   test = scale(***), \n",
    "                   cl = ***,\n",
    "                   k = 1)\n",
    "str(pred.knn1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El único parámetro a ajustar en la técnica k-NN es k (número de vecinos). Utilizaremos el paquete *caret* para encontrar el k óptimo en nuestro problema. Para ello, considera una cross-validación con 10 folds sobre el dataset de train barriendo todos los k impares desde 1 a 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(caret)\n",
    "## finding optimum k\n",
    "trctrl = trainControl(***)\n",
    "knn.opt = train(***\n",
    "                method = \"knn\",\n",
    "                trControl = trctrl,\n",
    "                preProcess = ***,\n",
    "                ***)\n",
    "plot(knn.opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliza este *k* óptimo para predecir en el test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction for test (with optimum k)\n",
    "pred.knn.opt = knn(train = scale(***), \n",
    "                   test = scale(***), \n",
    "                   cl = ***,\n",
    "                   k = ***)\n",
    "str(pred.knn.opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcula el accuracy y la correlación que se obtiene con las dos predicciones (con *k=1* y con *k=óptimo*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## validation\n",
    "# accuracy\n",
    "acc.knn1 = ***\n",
    "acc.knn.opt = ***\n",
    "print(c(acc.knn1, acc.knn.opt))\n",
    "\n",
    "# correlation\n",
    "cor.knn1 = ***\n",
    "cor.knn.opt = ***\n",
    "print(c(cor.knn1, cor.knn.opt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
