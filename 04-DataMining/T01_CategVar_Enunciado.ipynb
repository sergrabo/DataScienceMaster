{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Minería-de-Datos-(Master-en-Data-Science,-UIMP-UC)\" data-toc-modified-id=\"Minería-de-Datos-(Master-en-Data-Science,-UIMP-UC)-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Minería de Datos (Master en Data Science, UIMP-UC)</a></span></li><li><span><a href=\"#Tarea-1.-Variables-Categóricas:-Reglas-de-Asociación-y-Árboles-de-Clasificación\" data-toc-modified-id=\"Tarea-1.-Variables-Categóricas:-Reglas-de-Asociación-y-Árboles-de-Clasificación-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Tarea 1. Variables Categóricas: Reglas de Asociación y Árboles de Clasificación</a></span><ul class=\"toc-item\"><li><span><a href=\"#[Profesores:-Joaquín-Bedia,-Rodrigo-García-y--Sixto-Herrera]\" data-toc-modified-id=\"[Profesores:-Joaquín-Bedia,-Rodrigo-García-y--Sixto-Herrera]-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>[Profesores: Joaquín Bedia, Rodrigo García y  Sixto Herrera]</a></span></li><li><span><a href=\"#Punto-1-(3-puntos):\" data-toc-modified-id=\"Punto-1-(3-puntos):-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Punto 1 (3 puntos):</a></span></li><li><span><a href=\"#Punto-2-(4-puntos):\" data-toc-modified-id=\"Punto-2-(4-puntos):-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Punto 2 (4 puntos):</a></span></li><li><span><a href=\"#Punto-3-(3-puntos):\" data-toc-modified-id=\"Punto-3-(3-puntos):-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Punto 3 (3 puntos):</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Minería de Datos (Master en Data Science, UIMP-UC) \n",
    "## Tarea 1. Variables Categóricas: Reglas de Asociación y Árboles de Clasificación\n",
    "### [Profesores: Joaquín Bedia, Rodrigo García y  Sixto Herrera]\n",
    "\n",
    "En la presente tarea consideraremos el dataset `Mushroom`, incluido tanto en la La librería [arulesViz](https://cran.r-project.org/web/packages/arulesViz/arulesViz.pdf) como en las diferentes plataformas descritas en el marco de la asignatura y en el GitHub dedicado a este Máster ([Mushroom](https://github.com/SantanderMetGroup/Master-Data-Science/blob/master/Data_mining/datasets/mushrooms.csv.)), para aplicar las diferentes técnicas vistas en el curso para variables categóricas: Reglas de Asociación y Árboles de Clasificación.\n",
    "\n",
    "Para el desarrollo de la tarea se permitirá el uso de todo el material incluido en el Moodle de las asignatura así como el desarrollado por el alumno durante la realización de las prácticas.\n",
    "\n",
    "La entrega consisitirá de un notebook de Jupyter ó un R-MarkDown, junto con el archivo html que éste genera. Ambos ficheros se entregarán a través del Moodle de la asignatura en la tarea correspondiente.\n",
    "\n",
    "### Punto 1 (3 puntos):\n",
    "\n",
    "Considerar uno de los algoritmos de asociación vistos en clase y obtener las reglas representativas del dataset fijando los parámetros de aprendizaje (soporte, confianza, etc...). Analizar los resultados en términos generales:\n",
    "* ¿Cuantas reglas se han generado?\n",
    "* ¿Existe alguna regla redundante?, ¿Cuántas?\n",
    "* ¿Existe alguna regla que incluya la variable objetivo: `Class=edible` ó `Class=poisonous`?, ¿Cuantas?\n",
    "* De cara a ser utilizada como modelo predictivo es adecuado que la variable objetivo se encuentre en el consecuente de la regla de asociación, ¿se da esta propiedad en alguna regla?\n",
    "* Considerar los subconjuntos de reglas con ambas clases como consecuente e ilustrar las variables implicadas en cada caso. Considerar alguno de los grafos vistos para apoyar las conclusiones obtenidas.\n",
    "\n",
    "NOTA: Usar soportes superiores a 0.1 para evitar problemas de memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Punto 2 (4 puntos):\n",
    "\n",
    "En este apartado aplicaremos árboles de clasificación para obtener un modelo que permita clasificar una nueva entrada. Para ello, vamos a utilizar el paquete `CaReT`. Este paquete (y los demás que hemos visto para trabajar con árboles en `R`) no aceptan objetos del tipo `transactions` como los del apartado anterior. Por tanto, hemos preparado un fichero *csv* con el dataset *Mushrooms*; puedes descargarlo desde esta aquí:\n",
    "https://github.com/SantanderMetGroup/Master-Data-Science/tree/master/Data_mining/datasets. Puedes leer este dataset con la función `read.csv`.  \n",
    "Ahora ya tenemos un data.frame con el que podemos empezar a trabajar. En primer lugar tendremos que eliminar la columna 17 (`veil.type`), ya que contiene un único nivel y daría errores en `CaReT`(esta columna podría eliminarse también en el caso de las reglas de asociación ya que no aporta información al dataset).  \n",
    "Nuestro objetivo será encontrar la configuración (profundidad) óptima del árbol. Para ello, dividiremos el dataset en dos subconjuntos indpendedientes de train y test (75% y 25% del total, respectivamente). Sobre el dataset de train, aplicaremos una cross-validación con 3 folds y la repetiremos 50 veces (recuerda que los árboles son sensibles a la partición train/test que se considere). \n",
    "\n",
    "* ¿Cuál es la configuración óptima del árbol? ¿Hay alguna diferencia entre el árbol *completo* y el óptimo? ¿Por qué crees que ocurre esto?\n",
    "* ¿Cuáles son las dos variables que mayor peso tienen a la hora de clasificar? Entrena un nuevo árbol considerando como predictores únicamente esas dos variables. ¿Qué resultados obtienes? \n",
    "* Entrena un nuevo árbol considerando como predictores cualesquiera otras dos variables que no sean las utilizadas en la pregunta anterior. ¿Cuál es el error de test de este árbol?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Punto 3 (3 puntos):\n",
    "\n",
    "Por un lado, las ramas del árbol pueden ser interpretadas como reglas de forma similar a las obtenidas por el algoritmo de reglas aplicado. Por ejemplo, en el caso del árbol obtenido con el dataset `Play Tennis` puede obtenerse las siguientes `reglas`: SI Outlook = Overcast -> Play Tennis = Yes ó SI (Outlook = Sunny) AND (Humidity = Normal) -> Play Tennis = Yes, cuya confianza asociada viene dada por la frecuencia relativa de cada caso en esa rama del árbol. Por otro lado, considerando las reglas que implican a nuestra variable objetivo tendríamos un `modelo` similar al dado por el árbol. Considerar y comparar ambas aproximaciones (p.e. ¿coinciden los antecedentes de las reglas? ¿alguna de las variables más frecuentes como antecedente en las reglas se corresponde con alguna de las variables con mayor capacidad de discriminación? etc.). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
